{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Accent Classifier - Interactive Demo\n",
        "\n",
        "Welcome to the Accent Classifier interactive demonstration! This notebook provides a comprehensive walkthrough of the accent classification system, from training with Google Text-to-Speech samples to analyzing real audio files.\n",
        "\n",
        "## üéØ What You'll Learn\n",
        "\n",
        "- How to train the accent classifier with TTS-generated samples\n",
        "- Audio processing and feature extraction techniques  \n",
        "- Real-time accent classification from audio files\n",
        "- Performance analysis and visualization\n",
        "- Advanced usage patterns and customization\n",
        "\n",
        "## üìã Prerequisites\n",
        "\n",
        "Make sure you have installed all required dependencies:\n",
        "```bash\n",
        "pip install -r ../requirements.txt\n",
        "pip install jupyter notebook  # If not already installed\n",
        "```\n",
        "\n",
        "## üöÄ Getting Started\n",
        "\n",
        "Run each cell in order to:\n",
        "1. **Generate Google TTS training samples**\n",
        "2. **Train the machine learning model**\n",
        "3. **Analyze audio features and processing**\n",
        "4. **Test accent classification**\n",
        "5. **Visualize performance results**\n",
        "6. **Explore advanced features**\n",
        "\n",
        "---\n",
        "\n",
        "*This notebook demonstrates the complete workflow from TTS generation to production usage.*\n",
        "\n",
        "## üë®‚Äçüíª Developer & Company\n",
        "\n",
        "**Developed by:** [Kayode Femi Amoo (Nifemi Alpine)](https://x.com/usecodenaija)  \n",
        "**Twitter:** [@usecodenaija](https://twitter.com/usecodenaija)  \n",
        "**Company:** [CIVAI Technologies](https://civai.co)  \n",
        "**Website:** [https://civai.co](https://civai.co)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add the parent directory to the path to import our modules\n",
        "sys.path.append('..')\n",
        "\n",
        "# Import our accent classifier modules\n",
        "from src.audio_processor import AudioProcessor\n",
        "from src.feature_extractor import FeatureExtractor\n",
        "from src.model_handler import AccentModelHandler\n",
        "from src.audio_generator import ScalableAudioGenerator\n",
        "\n",
        "# Setup plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(f\"üìÅ Working directory: {os.getcwd()}\")\n",
        "print(f\"üêç Python version: {sys.version}\")\n",
        "print(\"üéä Ready to start the accent classification demo!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complete Accent Classification Workflow Demo\n",
        "print(\"üé™ Accent Classification Complete Workflow\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Step 1: Initialize components\n",
        "print(\"üîß Step 1: Initializing components...\")\n",
        "audio_gen = ScalableAudioGenerator()\n",
        "model_handler = AccentModelHandler()\n",
        "audio_processor = AudioProcessor()\n",
        "feature_extractor = FeatureExtractor()\n",
        "\n",
        "# Step 2: Check/Generate training data\n",
        "print(\"\\nüéµ Step 2: Checking training data...\")\n",
        "try:\n",
        "    info = audio_gen.get_training_info()\n",
        "    total_samples = sum(data['sample_count'] for data in info.values())\n",
        "    print(f\"  üìä Found {total_samples} existing samples across {len(info)} languages\")\n",
        "    \n",
        "    if total_samples < 10:  # Generate if we don't have enough\n",
        "        print(\"  üé§ Generating additional TTS samples...\")\n",
        "        results = audio_gen.generate_samples(\n",
        "            languages=['american', 'british', 'french', 'german'],\n",
        "            num_samples=3,\n",
        "            force_regenerate=False\n",
        "        )\n",
        "        print(\"  ‚úÖ Sample generation complete\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"  ‚ö†Ô∏è  No existing data found: {e}\")\n",
        "    print(\"  üé§ Generating fresh TTS samples...\")\n",
        "    try:\n",
        "        results = audio_gen.generate_samples(\n",
        "            languages=['american', 'british', 'french'],\n",
        "            num_samples=3,\n",
        "            force_regenerate=True\n",
        "        )\n",
        "        print(\"  ‚úÖ Fresh samples generated successfully\")\n",
        "    except Exception as gen_error:\n",
        "        print(f\"  ‚ùå Sample generation failed: {gen_error}\")\n",
        "\n",
        "# Step 3: Train the model\n",
        "print(\"\\nüß† Step 3: Training the model...\")\n",
        "try:\n",
        "    training_results = model_handler.train_model(use_tts=True, verbose=False)\n",
        "    print(f\"  üéØ Training accuracy: {training_results.get('accuracy', 0):.1%}\")\n",
        "    print(f\"  üìä Cross-validation: {training_results.get('cv_score', 0):.1%}\")\n",
        "    print(f\"  üåê Supported accents: {len(training_results.get('class_names', []))}\")\n",
        "except Exception as e:\n",
        "    print(f\"  ‚ùå Training failed: {e}\")\n",
        "    print(\"  üí° Try generating TTS samples first\")\n",
        "\n",
        "print(\"\\nüéâ Workflow initialization complete!\")\n",
        "print(\"üìù Run the following cells to explore features, classify audio, and analyze results.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive Audio Classification Demo\n",
        "def classify_and_analyze(audio_file_path=None):\n",
        "    \"\"\"\n",
        "    Classify an audio file and show detailed analysis.\n",
        "    If no path provided, uses the first available sample.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Find an audio file to analyze\n",
        "    if not audio_file_path:\n",
        "        audio_samples_dir = Path('../audio_samples')\n",
        "        for lang_dir in audio_samples_dir.iterdir():\n",
        "            if lang_dir.is_dir():\n",
        "                for audio_file in lang_dir.glob('*.wav'):\n",
        "                    audio_file_path = str(audio_file)\n",
        "                    break\n",
        "                if audio_file_path:\n",
        "                    break\n",
        "    \n",
        "    if not audio_file_path or not os.path.exists(audio_file_path):\n",
        "        print(\"‚ùå No audio file found. Please generate TTS samples first.\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"üéß Analyzing: {os.path.basename(audio_file_path)}\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        # Load and analyze audio\n",
        "        audio_data = audio_processor.load_audio(audio_file_path)\n",
        "        print(f\"‚è±Ô∏è  Duration: {audio_data['duration']:.2f}s\")\n",
        "        print(f\"üîä Sample Rate: {audio_data['sample_rate']} Hz\")\n",
        "        print(f\"‚ö° RMS Energy: {audio_data['rms_energy']:.4f}\")\n",
        "        \n",
        "        # Extract features\n",
        "        features = feature_extractor.extract_features(\n",
        "            audio_data['audio'], \n",
        "            audio_data['sample_rate']\n",
        "        )\n",
        "        print(f\"üîç Extracted {len(features)} features\")\n",
        "        \n",
        "        # Classify accent\n",
        "        result = model_handler.classify_audio(audio_file_path)\n",
        "        \n",
        "        print(f\"\\nüéØ Classification Results:\")\n",
        "        print(f\"  üåç Predicted Accent: {result['accent_name']}\")\n",
        "        print(f\"  üìä Confidence: {result['confidence']:.1%}\")\n",
        "        print(f\"  ‚úÖ Reliable: {'Yes' if result['reliable'] else 'No'}\")\n",
        "        \n",
        "        # Show probability breakdown\n",
        "        if 'all_probabilities' in result:\n",
        "            print(f\"\\nüìà All Probabilities:\")\n",
        "            sorted_probs = sorted(result['all_probabilities'].items(), \n",
        "                                key=lambda x: x[1], reverse=True)\n",
        "            for accent, prob in sorted_probs:\n",
        "                bar = \"‚ñà\" * int(prob * 30)\n",
        "                print(f\"  {accent:.<20} {prob:.1%} {bar}\")\n",
        "        \n",
        "        return result\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error analyzing audio: {e}\")\n",
        "        return None\n",
        "\n",
        "# Run the demo\n",
        "print(\"üé™ Interactive Audio Classification Demo\")\n",
        "print(\"=\" * 50)\n",
        "result = classify_and_analyze()\n",
        "\n",
        "if result:\n",
        "    print(f\"\\nüí° To analyze your own audio file, use:\")\n",
        "    print(f\"   classify_and_analyze('/path/to/your/audio.wav')\")\n",
        "    print(f\"\\nüîß You can also run individual components:\")\n",
        "    print(f\"   audio_data = audio_processor.load_audio('file.wav')\")\n",
        "    print(f\"   features = feature_extractor.extract_features(audio, sr)\")\n",
        "    print(f\"   result = model_handler.classify_audio('file.wav')\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batch Testing and Performance Analysis\n",
        "def batch_test_performance():\n",
        "    \"\"\"Test the classifier on multiple samples and analyze performance.\"\"\"\n",
        "    \n",
        "    print(\"üìä Batch Performance Testing\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Collect test samples\n",
        "    audio_samples_dir = Path('../audio_samples')\n",
        "    test_samples = []\n",
        "    \n",
        "    for lang_dir in audio_samples_dir.iterdir():\n",
        "        if lang_dir.is_dir():\n",
        "            audio_files = list(lang_dir.glob('*.wav'))[:3]  # Max 3 per language\n",
        "            for audio_file in audio_files:\n",
        "                test_samples.append({\n",
        "                    'path': str(audio_file),\n",
        "                    'true_accent': lang_dir.name,\n",
        "                    'file_name': audio_file.name\n",
        "                })\n",
        "    \n",
        "    if not test_samples:\n",
        "        print(\"‚ùå No test samples found. Generate TTS samples first.\")\n",
        "        return\n",
        "    \n",
        "    print(f\"üß™ Testing {len(test_samples)} samples...\\n\")\n",
        "    \n",
        "    # Test each sample\n",
        "    results = []\n",
        "    for i, sample in enumerate(test_samples, 1):\n",
        "        try:\n",
        "            result = model_handler.classify_audio(sample['path'])\n",
        "            \n",
        "            is_correct = sample['true_accent'] == result['accent']\n",
        "            results.append({\n",
        "                'file': sample['file_name'],\n",
        "                'true': sample['true_accent'],\n",
        "                'predicted': result['accent'],\n",
        "                'confidence': result['confidence'],\n",
        "                'reliable': result['reliable'],\n",
        "                'correct': is_correct\n",
        "            })\n",
        "            \n",
        "            # Progress indicator\n",
        "            status = \"‚úÖ\" if is_correct and result['reliable'] else \"‚ö†Ô∏è\" if is_correct else \"‚ùå\"\n",
        "            print(f\"[{i:2d}/{len(test_samples)}] {status} {sample['file_name']:25} \"\n",
        "                  f\"{sample['true_accent']:10} ‚Üí {result['accent']:10} \"\n",
        "                  f\"({result['confidence']:.2f})\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"[{i:2d}/{len(test_samples)}] ‚ùå Error: {sample['file_name']} - {e}\")\n",
        "    \n",
        "    # Calculate metrics\n",
        "    if results:\n",
        "        accuracy = sum(r['correct'] for r in results) / len(results)\n",
        "        reliable_count = sum(r['reliable'] for r in results)\n",
        "        avg_confidence = np.mean([r['confidence'] for r in results])\n",
        "        \n",
        "        reliable_results = [r for r in results if r['reliable']]\n",
        "        reliable_accuracy = (sum(r['correct'] for r in reliable_results) / \n",
        "                           len(reliable_results) if reliable_results else 0)\n",
        "        \n",
        "        print(f\"\\nüìà Performance Summary:\")\n",
        "        print(f\"  üéØ Overall Accuracy: {accuracy:.1%} ({sum(r['correct'] for r in results)}/{len(results)})\")\n",
        "        print(f\"  ‚úÖ Reliable Predictions: {reliable_count}/{len(results)} ({reliable_count/len(results):.1%})\")\n",
        "        print(f\"  üéØ Reliable Accuracy: {reliable_accuracy:.1%}\")\n",
        "        print(f\"  üìä Average Confidence: {avg_confidence:.2f}\")\n",
        "        \n",
        "        # Create simple visualization\n",
        "        if len(results) > 1:\n",
        "            print(f\"\\nüìä Accuracy by Language:\")\n",
        "            df = pd.DataFrame(results)\n",
        "            lang_accuracy = df.groupby('true')['correct'].mean().sort_values(ascending=False)\n",
        "            for lang, acc in lang_accuracy.items():\n",
        "                bar = \"‚ñà\" * int(acc * 20)\n",
        "                print(f\"  {lang:12} {acc:.1%} {bar}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Run batch testing\n",
        "batch_results = batch_test_performance()\n",
        "\n",
        "if batch_results:\n",
        "    print(f\"\\nüí° Results stored in 'batch_results' variable for further analysis\")\n",
        "    print(f\"üîç Try: pd.DataFrame(batch_results) to explore the data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Audio Visualization and Feature Analysis\n",
        "def visualize_audio_features(audio_file_path=None):\n",
        "    \"\"\"Create visualizations of audio features and classification.\"\"\"\n",
        "    \n",
        "    # Find an audio file if none provided\n",
        "    if not audio_file_path:\n",
        "        audio_samples_dir = Path('../audio_samples')\n",
        "        for lang_dir in audio_samples_dir.iterdir():\n",
        "            if lang_dir.is_dir():\n",
        "                audio_files = list(lang_dir.glob('*.wav'))\n",
        "                if audio_files:\n",
        "                    audio_file_path = str(audio_files[0])\n",
        "                    break\n",
        "    \n",
        "    if not audio_file_path or not os.path.exists(audio_file_path):\n",
        "        print(\"‚ùå No audio file found for visualization\")\n",
        "        return\n",
        "    \n",
        "    print(f\"üé® Visualizing: {os.path.basename(audio_file_path)}\")\n",
        "    \n",
        "    try:\n",
        "        # Load audio with librosa for visualization\n",
        "        import librosa\n",
        "        import librosa.display\n",
        "        \n",
        "        y, sr = librosa.load(audio_file_path, sr=16000)\n",
        "        \n",
        "        # Create comprehensive visualization\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle(f'Audio Analysis: {os.path.basename(audio_file_path)}', fontsize=16)\n",
        "        \n",
        "        # 1. Waveform\n",
        "        time = np.linspace(0, len(y)/sr, len(y))\n",
        "        axes[0, 0].plot(time, y, alpha=0.8)\n",
        "        axes[0, 0].set_title('Waveform')\n",
        "        axes[0, 0].set_xlabel('Time (s)')\n",
        "        axes[0, 0].set_ylabel('Amplitude')\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # 2. Spectrogram\n",
        "        D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "        img = librosa.display.specshow(D, y_axis='hz', x_axis='time', sr=sr, ax=axes[0, 1])\n",
        "        axes[0, 1].set_title('Spectrogram')\n",
        "        plt.colorbar(img, ax=axes[0, 1], format='%+2.0f dB')\n",
        "        \n",
        "        # 3. MFCC\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "        img = librosa.display.specshow(mfccs, x_axis='time', ax=axes[0, 2])\n",
        "        axes[0, 2].set_title('MFCC Features')\n",
        "        axes[0, 2].set_ylabel('MFCC Coefficients')\n",
        "        plt.colorbar(img, ax=axes[0, 2])\n",
        "        \n",
        "        # 4. Chroma\n",
        "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "        img = librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', ax=axes[1, 0])\n",
        "        axes[1, 0].set_title('Chroma Features')\n",
        "        plt.colorbar(img, ax=axes[1, 0])\n",
        "        \n",
        "        # 5. Spectral Features\n",
        "        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
        "        frames = range(len(spectral_centroids))\n",
        "        t = librosa.frames_to_time(frames, sr=sr)\n",
        "        axes[1, 1].plot(t, spectral_centroids, alpha=0.8, label='Spectral Centroid')\n",
        "        axes[1, 1].set_title('Spectral Centroid')\n",
        "        axes[1, 1].set_xlabel('Time (s)')\n",
        "        axes[1, 1].set_ylabel('Hz')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # 6. Classification Result\n",
        "        result = model_handler.classify_audio(audio_file_path)\n",
        "        if 'all_probabilities' in result:\n",
        "            probs = result['all_probabilities']\n",
        "            accents = list(probs.keys())\n",
        "            probabilities = list(probs.values())\n",
        "            \n",
        "            bars = axes[1, 2].bar(range(len(accents)), probabilities, alpha=0.7)\n",
        "            axes[1, 2].set_title('Classification Probabilities')\n",
        "            axes[1, 2].set_ylabel('Probability')\n",
        "            axes[1, 2].set_xticks(range(len(accents)))\n",
        "            axes[1, 2].set_xticklabels([a.split()[0] for a in accents], rotation=45)\n",
        "            \n",
        "            # Highlight the prediction\n",
        "            max_idx = probabilities.index(max(probabilities))\n",
        "            bars[max_idx].set_color('red')\n",
        "            bars[max_idx].set_alpha(1.0)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Print classification details\n",
        "        print(f\"\\nüéØ Classification Result:\")\n",
        "        print(f\"  Predicted: {result['accent_name']}\")\n",
        "        print(f\"  Confidence: {result['confidence']:.1%}\")\n",
        "        print(f\"  Reliable: {'Yes' if result['reliable'] else 'No'}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Visualization error: {e}\")\n",
        "        print(\"üí° Make sure librosa is installed: pip install librosa\")\n",
        "\n",
        "# Create visualization\n",
        "print(\"üé® Audio Feature Visualization\")\n",
        "print(\"=\" * 50)\n",
        "visualize_audio_features()\n",
        "\n",
        "print(f\"\\nüí° To visualize a specific file, use:\")\n",
        "print(f\"   visualize_audio_features('/path/to/your/audio.wav')\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üéâ Summary and Next Steps\n",
        "\n",
        "Congratulations! You've successfully explored the Accent Classifier system. Here's what we covered and what you can do next.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo Summary and Resources\n",
        "print(\"üéä Accent Classifier Demo Complete!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Summary of what we covered\n",
        "summary_items = [\n",
        "    \"‚úÖ Initialized and configured the accent classification system\",\n",
        "    \"‚úÖ Generated high-quality TTS training samples using Google Text-to-Speech\",\n",
        "    \"‚úÖ Trained machine learning models for accent classification\",\n",
        "    \"‚úÖ Analyzed audio processing and feature extraction techniques\",\n",
        "    \"‚úÖ Performed real-time accent classification on audio samples\",\n",
        "    \"‚úÖ Conducted batch testing and performance analysis\",\n",
        "    \"‚úÖ Created comprehensive audio feature visualizations\",\n",
        "    \"‚úÖ Explored advanced system capabilities and configurations\"\n",
        "]\n",
        "\n",
        "print(\"üìã What We Accomplished:\")\n",
        "for item in summary_items:\n",
        "    print(f\"  {item}\")\n",
        "\n",
        "print(f\"\\nüöÄ Next Steps - Try These:\")\n",
        "next_steps = [\n",
        "    \"üé§ Test with your own audio files using classify_and_analyze('/path/to/file.wav')\",\n",
        "    \"üåç Add new languages by creating config files in audio_samples/new_language/\",\n",
        "    \"üîß Experiment with different confidence thresholds for reliability\",\n",
        "    \"üìä Analyze larger datasets using the batch testing functions\",\n",
        "    \"üé® Create custom visualizations using the extracted features\",\n",
        "    \"üöÄ Integrate the system into your own applications\",\n",
        "    \"üìà Train with real-world audio data for improved accuracy\"\n",
        "]\n",
        "\n",
        "for step in next_steps:\n",
        "    print(f\"  {step}\")\n",
        "\n",
        "print(f\"\\nüìö Key Resources:\")\n",
        "resources = [\n",
        "    \"üìñ Documentation: Check the docs/ directory for detailed guides\",\n",
        "    \"üß™ Testing: Run pytest tests/ for comprehensive test coverage\",\n",
        "    \"üéØ CLI Usage: python accent_classifier.py --help for command-line options\",\n",
        "    \"üîÑ Sample Generation: python src/audio_generator.py --help for TTS options\",\n",
        "    \"üåê GitHub: Check for updates and contribute to the project\"\n",
        "]\n",
        "\n",
        "for resource in resources:\n",
        "    print(f\"  {resource}\")\n",
        "\n",
        "print(f\"\\nüí° Production Usage Examples:\")\n",
        "production_examples = [\n",
        "    \"# Train with fresh samples\",\n",
        "    \"python accent_classifier.py --train --use-tts --fresh --verbose\",\n",
        "    \"\",\n",
        "    \"# Classify a single file\",\n",
        "    \"python accent_classifier.py --file audio.wav --verbose\",\n",
        "    \"\",\n",
        "    \"# Batch process directory\",\n",
        "    \"python accent_classifier.py --batch audio_files/ --output results/\",\n",
        "    \"\",\n",
        "    \"# Real-time microphone input\",\n",
        "    \"python accent_classifier.py --microphone --duration 10\"\n",
        "]\n",
        "\n",
        "for example in production_examples:\n",
        "    print(f\"  {example}\")\n",
        "\n",
        "print(f\"\\nü§ù Contributing:\")\n",
        "print(f\"  The Accent Classifier is designed to be extensible and community-driven.\")\n",
        "print(f\"  Contributions welcome for new languages, improved models, and features!\")\n",
        "\n",
        "print(f\"\\nüé≠ Thank you for exploring the Accent Classifier!\")\n",
        "print(f\"   This notebook demonstrated the full pipeline from TTS generation\")\n",
        "print(f\"   to production-ready accent classification. Happy coding! üöÄ\")\n",
        "\n",
        "print(f\"\\nüë®‚Äçüíª Developed by: Kayode Femi Amoo (Nifemi Alpine) - @usecodenaija\")\n",
        "print(f\"üè¢ Company: CIVAI Technologies - https://civai.co\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
